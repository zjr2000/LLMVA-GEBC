model:
  arch: video_blip2_opt_gebc
  model_type: pretrain_vicuna
  # OPT
  opt_model: facebook/opt-13b
  # opt project 
  frozen_opt_proj: False
  num_video_query_token: 32
  max_frame_pos: 32
  max_other_features_pos: 128
  q_former_hidden_size: 768
  max_txt_len: 30
  end_sym: "\n"
  ckpt: '.cache/pretrain-vicuna13b.pth'
  other_feat_total_size: 3072
  num_other_feat_query_token: 6

datasets:
  gebc:
    data_type: video
    build_info:
      video_info_path: data/annotations/video_info.json
      q_former_feature_folder: data/features/eva_vit_g_q_former_tokens_12
      
      other_feature_names: ['intern_video', 'omni', 'clip']
      other_feature_folders: ['/nvme-ssd/wt/yunlong/Video-LLaMA-GEBC/data/features/intern_video_feat_8', 'data/features/omnivore_fps_15_len_16_stride_1_rename', 'data/features/clip_fps_15_stride_1_rename']
      max_seq_len: 64
      annotations:
        train:
          annotation_path: data/annotations/train_all_annotation.json
        val:
          annotation_path: data/annotations/valset_highest_f1.json
        test:
          annotation_path: data/annotations/test_timestamp.json

run:
  task: boundary_captioning
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 8e-5
  min_lr: 1e-5
  warmup_lr: 1e-6
  weight_decay: 0.001
  max_epoch: 5
  batch_size_train: 16
  batch_size_eval: 8
  num_workers: 4
  warmup_steps: 5000
  seed: 42
  output_dir: "output/video_blip2_opt13b_full_12frame_intern_omni_clip_8e5"
  amp: True
  resume_ckpt_path: null
  evaluate: False
  train_splits: ["train"]
  valid_splits: ["val"]
  test_splits: ["test"]
  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: False
  num_beams: 2 
  max_len: 30
  min_len: 1