model:
  arch: video_blip2_opt_gebc
  model_type: pretrain_vicuna
  # OPT
  opt_model: facebook/opt-125m
  # opt project 
  frozen_opt_proj: False
  num_video_query_token: 32
  max_frame_pos: 36 # need to >= max_seq_len, use omni with 100
  max_other_features_pos: 100
  q_former_hidden_size: 768
  max_txt_len: 30
  end_sym: "\n"
  other_feat_total_size: 768
  num_other_feat_query_token: 6

datasets:
  gebc:
    data_type: video
    build_info:
      video_info_path: data/annotations/video_info.json
      q_former_feature_folder: data/features/eva_vit_g_q_former_tokens_8
      # other_feature_names: ['intern_video', 'omni']
      other_feature_names: ['intern_video']
      # other_feature_folders: ['data/features/intern_video_feat_8', 'data/features/omni_gebc']
      other_feature_folders: ['/nvme-ssd/wt/yunlong/Video-LLaMA-GEBC/data/features/intern_video_feat_8']
      
      max_seq_len: 36 # need to <= max_frame_pos
      annotations:
        train:
          annotation_path: data/annotations/trainset_highest_f1.json #data/annotations/trainset_highest_f1.json
        val:
          annotation_path: data/annotations/valset_highest_f1.json
        test:
          annotation_path: data/annotations/test_timestamp.json

run:
  task: boundary_captioning
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 1e-4
  iters_per_epoch: 50
  min_lr: 8e-5
  warmup_lr: 1e-6
  weight_decay: 0.001
  max_epoch: 5
  batch_size_train: 16
  batch_size_eval: 16
  num_workers: 4
  warmup_steps: 1000
  seed: 42
  output_dir: "output/debug"
  amp: True
  resume_ckpt_path: null
  evaluate: False
  train_splits: ["train"]
  valid_splits: ["val"]
  test_splits: ["test"]
  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: False
  num_beams: 2 
  max_len: 30
  min_len: 1